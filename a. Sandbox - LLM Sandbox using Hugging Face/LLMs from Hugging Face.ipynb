{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "3.11.9 (main, Apr  2 2024, 08:25:04) [Clang 15.0.0 (clang-1500.3.9.4)]\n"
     ]
    }
   ],
   "source": [
    "import sys; print(sys.maxsize > 2**32)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAGIC %pip install sacremoses==0.0.53\n",
    "# MAGIC %pip install datasets\n",
    "# MAGIC %pip install transformers\n",
    "# MAGIC %pip install PyTorch\n",
    "# MAGIC %pip install TensorFlow\n",
    "# MAGIC %pip install Flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m xsum_dataset \u001b[38;5;241m=\u001b[39m load_dataset(\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxsum\u001b[39m\u001b[38;5;124m\"\u001b[39m, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, cache_dir\u001b[38;5;241m=\u001b[39m\u001b[43mDA\u001b[49m\u001b[38;5;241m.\u001b[39mpaths\u001b[38;5;241m.\u001b[39mdatasets\n\u001b[1;32m      3\u001b[0m )  \u001b[38;5;66;03m# Note: We specify cache_dir to use predownloaded data.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m xsum_dataset \n",
      "\u001b[0;31mNameError\u001b[0m: name 'DA' is not defined"
     ]
    }
   ],
   "source": [
    "xsum_dataset = load_dataset(\n",
    "    \"xsum\", version=\"1.2.0\", cache_dir=DA.paths.datasets\n",
    ")  # Note: We specify cache_dir to use predownloaded data.\n",
    "xsum_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsum_sample = xsum_dataset[\"train\"].select(range(10))\n",
    "display(xsum_sample.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=\"t5-small\",\n",
    "    min_length=20,\n",
    "    max_length=40,\n",
    "    truncation=True,\n",
    "    model_kwargs={\"cache_dir\": DA.paths.datasets},\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer(xsum_sample[\"document\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = summarizer(xsum_sample[\"document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "display(\n",
    "    pd.DataFrame.from_dict(results)\n",
    "    .rename({\"summary_text\": \"generated_summary\"}, axis=1)\n",
    "    .join(pd.DataFrame.from_dict(xsum_sample))[\n",
    "        [\"generated_summary\", \"summary\", \"document\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "poem_dataset = load_dataset(\n",
    "    \"poem_sentiment\", version=\"1.0.0\", cache_dir=DA.paths.datasets\n",
    ")\n",
    "poem_sample = poem_dataset[\"train\"].select(range(10))\n",
    "display(poem_sample.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classifier = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"nickwong64/bert-base-uncased-poems-sentiment\",\n",
    "    model_kwargs={\"cache_dir\": DA.paths.datasets},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sentiment_classifier(poem_sample[\"verse_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data = (\n",
    "    pd.DataFrame.from_dict(results)\n",
    "    .rename({\"label\": \"predicted_label\"}, axis=1)\n",
    "    .join(pd.DataFrame.from_dict(poem_sample).rename({\"label\": \"true_label\"}, axis=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_labels = {0: \"negative\", 1: \"positive\", 2: \"no_impact\", 3: \"mixed\"}\n",
    "joined_data = joined_data.replace({\"true_label\": sentiment_labels})\n",
    "\n",
    "display(joined_data[[\"predicted_label\", \"true_label\", \"score\", \"verse_text\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_to_es_translation_pipeline = pipeline(\n",
    "    task=\"translation\",\n",
    "    model=\"Helsinki-NLP/opus-mt-en-es\",\n",
    "    model_kwargs={\"cache_dir\": DA.paths.datasets},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_to_es_translation_pipeline(\n",
    "    \"Existing, open-source (and proprietary) models can be used out-of-the-box for many applications.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_small_pipeline = pipeline(\n",
    "    task=\"text2text-generation\",\n",
    "    model=\"t5-small\",\n",
    "    max_length=50,\n",
    "    model_kwargs={\"cache_dir\": DA.paths.datasets},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_small_pipeline(\n",
    "    \"translate English to French: Existing, open-source (and proprietary) models can be used out-of-the-box for many applications.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_small_pipeline(\n",
    "    \"translate English to Romanian: Existing, open-source (and proprietary) models can be used out-of-the-box for many applications.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_article(article: str) -> None:\n",
    "    \"\"\"\n",
    "    This helper function defines the categories (labels) which the model must use to label articles.\n",
    "    Note that our model was NOT fine-tuned to use these specific labels,\n",
    "    but it \"knows\" what the labels mean from its more general training.\n",
    "\n",
    "    This function then prints out the predicted labels alongside their confidence scores.\n",
    "    \"\"\"\n",
    "    results = zero_shot_pipeline(\n",
    "        article,\n",
    "        candidate_labels=[\n",
    "            \"politics\",\n",
    "            \"finance\",\n",
    "            \"sports\",\n",
    "            \"science and technology\",\n",
    "            \"pop culture\",\n",
    "            \"breaking news\",\n",
    "        ],\n",
    "    )\n",
    "    # Print the results nicely\n",
    "    del results[\"sequence\"]\n",
    "    display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorize_article(\n",
    "    \"\"\"\n",
    "Simone Favaro got the crucial try with the last move of the game, following earlier touchdowns by Chris Fusaro, Zander Fagerson and Junior Bulumakau.\n",
    "Rynard Landman and Ashton Hewitt got a try in either half for the Dragons.\n",
    "Glasgow showed far superior strength in depth as they took control of a messy match in the second period.\n",
    "Home coach Gregor Townsend gave a debut to powerhouse Fijian-born Wallaby wing Taqele Naiyaravoro, and centre Alex Dunbar returned from long-term injury, while the Dragons gave first starts of the season to wing Aled Brew and hooker Elliot Dee.\n",
    "Glasgow lost hooker Pat McArthur to an early shoulder injury but took advantage of their first pressure when Rory Clegg slotted over a penalty on 12 minutes.\n",
    "It took 24 minutes for a disjointed game to produce a try as Sarel Pretorius sniped from close range and Landman forced his way over for Jason Tovey to convert - although it was the lock's last contribution as he departed with a chest injury shortly afterwards.\n",
    "Glasgow struck back when Fusaro drove over from a rolling maul on 35 minutes for Clegg to convert.\n",
    "But the Dragons levelled at 10-10 before half-time when Naiyaravoro was yellow-carded for an aerial tackle on Brew and Tovey slotted the easy goal.\n",
    "The visitors could not make the most of their one-man advantage after the break as their error count cost them dearly.\n",
    "It was Glasgow's bench experience that showed when Mike Blair's break led to a short-range score from teenage prop Fagerson, converted by Clegg.\n",
    "Debutant Favaro was the second home player to be sin-binned, on 63 minutes, but again the Warriors made light of it as replacement wing Bulumakau, a recruit from the Army, pounced to deftly hack through a bouncing ball for an opportunist try.\n",
    "The Dragons got back within striking range with some excellent combined handling putting Hewitt over unopposed after 72 minutes.\n",
    "However, Favaro became sinner-turned-saint as he got on the end of another effective rolling maul to earn his side the extra point with the last move of the game, Clegg converting.\n",
    "Dragons director of rugby Lyn Jones said: \"We're disappointed to have lost but our performance was a lot better [than against Leinster] and the game could have gone either way.\n",
    "\"Unfortunately too many errors behind the scrum cost us a great deal, though from where we were a fortnight ago in Dublin our workrate and desire was excellent.\n",
    "\"It was simply error count from individuals behind the scrum that cost us field position, it's not rocket science - they were correct in how they played and we had a few errors, that was the difference.\"\n",
    "Glasgow Warriors: Rory Hughes, Taqele Naiyaravoro, Alex Dunbar, Fraser Lyle, Lee Jones, Rory Clegg, Grayson Hart; Alex Allan, Pat MacArthur, Zander Fagerson, Rob Harley (capt), Scott Cummings, Hugh Blake, Chris Fusaro, Adam Ashe.\n",
    "Replacements: Fergus Scott, Jerry Yanuyanutawa, Mike Cusack, Greg Peterson, Simone Favaro, Mike Blair, Gregor Hunter, Junior Bulumakau.\n",
    "Dragons: Carl Meyer, Ashton Hewitt, Ross Wardle, Adam Warren, Aled Brew, Jason Tovey, Sarel Pretorius; Boris Stankovich, Elliot Dee, Brok Harris, Nick Crosswell, Rynard Landman (capt), Lewis Evans, Nic Cudd, Ed Jackson.\n",
    "Replacements: Rhys Buckley, Phil Price, Shaun Knight, Matthew Screech, Ollie Griffiths, Luc Jones, Charlie Davies, Nick Scott.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorize_article(\n",
    "    \"\"\"\n",
    "The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\n",
    "Repair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\n",
    "Trains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\n",
    "Many businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\n",
    "First Minister Nicola Sturgeon visited the area to inspect the damage.\n",
    "The waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\n",
    "Jeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\n",
    "However, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\n",
    "\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we're neglected or forgotten,\" she said.\n",
    "\"That may not be true but it is perhaps my perspective over the last few days.\n",
    "\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\n",
    "Meanwhile, a flood alert remains in place across the Borders because of the constant rain.\n",
    "Peebles was badly hit by problems, sparking calls to introduce more defences in the area.\n",
    "Scottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\n",
    "The Labour Party's deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\n",
    "He said it was important to get the flood protection plan right but backed calls to speed up the process.\n",
    "\"I was quite taken aback by the amount of damage that has been done,\" he said.\n",
    "\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\n",
    "He said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\n",
    "Have you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_pipeline = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"EleutherAI/gpt-neo-1.3B\",\n",
    "    max_new_tokens=10,\n",
    "    model_kwargs={\"cache_dir\": DA.paths.datasets},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token_id = few_shot_pipeline.tokenizer.encode(\"###\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "[Tweet]: \"This new music video was incredible\"\n",
    "[Sentiment]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "[Tweet]: \"This is the link to the article\"\n",
    "[Sentiment]: Neutral\n",
    "###\n",
    "[Tweet]: \"This new music video was incredible\"\n",
    "[Sentiment]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "[Tweet]: \"I hate it when my phone battery dies.\"\n",
    "[Sentiment]: Negative\n",
    "###\n",
    "[Tweet]: \"My day has been üëç\"\n",
    "[Sentiment]: Positive\n",
    "###\n",
    "[Tweet]: \"This is the link to the article\"\n",
    "[Sentiment]: Neutral\n",
    "###\n",
    "[Tweet]: \"This new music video was incredible\"\n",
    "[Sentiment]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each food, suggest a good drink pairing:\n",
    "\n",
    "[food]: tapas\n",
    "[drink]: wine\n",
    "###\n",
    "[food]: pizza\n",
    "[drink]: soda\n",
    "###\n",
    "[food]: jalapenos poppers\n",
    "[drink]: beer\n",
    "###\n",
    "[food]: scone\n",
    "[drink]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = few_shot_pipeline(\n",
    "    \"\"\"Given a word describing how someone is feeling, suggest a description of that person.  The description should not include the original word.\n",
    "\n",
    "[word]: happy\n",
    "[description]: smiling, laughing, clapping\n",
    "###\n",
    "[word]: nervous\n",
    "[description]: glancing around quickly, sweating, fidgeting\n",
    "###\n",
    "[word]: sleepy\n",
    "[description]: heavy-lidded, slumping, rubbing eyes\n",
    "###\n",
    "[word]: confused\n",
    "[description]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = few_shot_pipeline(\n",
    "    \"\"\"Generate a book summary from the title:\n",
    "\n",
    "[book title]: \"Stranger in a Strange Land\"\n",
    "[book description]: \"This novel tells the story of Valentine Michael Smith, a human who comes to Earth in early adulthood after being born on the planet Mars and raised by Martians, and explores his interaction with and eventual transformation of Terran culture.\"\n",
    "###\n",
    "[book title]: \"The Adventures of Tom Sawyer\"\n",
    "[book description]: \"This novel is about a boy growing up along the Mississippi River. It is set in the 1840s in the town of St. Petersburg, which is based on Hannibal, Missouri, where Twain lived as a boy. In the novel, Tom Sawyer has several adventures, often with his friend Huckleberry Finn.\"\n",
    "###\n",
    "[book title]: \"Dune\"\n",
    "[book description]: \"This novel is set in the distant future amidst a feudal interstellar society in which various noble houses control planetary fiefs. It tells the story of young Paul Atreides, whose family accepts the stewardship of the planet Arrakis. While the planet is an inhospitable and sparsely populated desert wasteland, it is the only source of melange, or spice, a drug that extends life and enhances mental abilities.  The story explores the multilayered interactions of politics, religion, ecology, technology, and human emotion, as the factions of the empire confront each other in a struggle for the control of Arrakis and its spice.\"\n",
    "###\n",
    "[book title]: \"Blue Mars\"\n",
    "[book description]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    "    max_new_tokens=50,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(xsum_sample.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer(xsum_sample[\"document\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer(xsum_sample[\"document\"][0], num_beams=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer(xsum_sample[\"document\"][0], do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer(xsum_sample[\"document\"][0], do_sample=True, top_k=10, top_p=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the pre-trained tokenizer and model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\", cache_dir=DA.paths.datasets)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\", cache_dir=DA.paths.datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = list(map(lambda article: \"summarize: \" + article, xsum_sample[\"document\"]))\n",
    "display(pd.DataFrame(articles, columns=[\"prompts\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    articles, max_length=1024, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "print(\"input_ids:\")\n",
    "print(inputs[\"input_ids\"])\n",
    "print(\"attention_mask:\")\n",
    "print(inputs[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids = model.generate(\n",
    "    inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    num_beams=2,\n",
    "    min_length=0,\n",
    "    max_length=40,\n",
    ")\n",
    "print(summary_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_summaries = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
    "display(pd.DataFrame(decoded_summaries, columns=[\"decoded_summaries\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", cache_dir=DA.paths.datasets)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"t5-small\", cache_dir=DA.paths.datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    articles, max_length=1024, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "summary_ids = model.generate(\n",
    "    inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    num_beams=2,\n",
    "    min_length=0,\n",
    "    max_length=40,\n",
    ")\n",
    "decoded_summaries = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
    "\n",
    "display(pd.DataFrame(decoded_summaries, columns=[\"decoded_summaries\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
